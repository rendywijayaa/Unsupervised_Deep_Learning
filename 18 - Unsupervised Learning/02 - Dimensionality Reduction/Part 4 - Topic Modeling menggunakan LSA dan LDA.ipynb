{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cleared-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words('indonesian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-register",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "champion-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta Dikangkangi Para Preman\\nKALAU tak pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penyimpangan di Setpres Seolah Terjadi Sekaran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Kekerasan, Elite agar Duduk Bersama\\nSeju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                teks\n",
       "0  Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...\n",
       "1  Jakarta Dikangkangi Para Preman\\nKALAU tak pun...\n",
       "2  Penyimpangan di Setpres Seolah Terjadi Sekaran...\n",
       "3  Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...\n",
       "4  Stop Kekerasan, Elite agar Duduk Bersama\\nSeju..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/kompas.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-surge",
   "metadata": {},
   "source": [
    "# Extract BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "creative-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "official-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rendywij\\Miniconda3\\envs\\jcop_usl\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(ngram_range=(1,2), tokenizer=word_tokenize, stop_words=sw_indo, min_df=5)\n",
    "bow_matrix = bow.fit_transform(df.teks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-mustang",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "contained-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bow.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "functional-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(model):\n",
    "    return[[vocab[idx] for idx in reversed(comp.argsort()[-6:]) if vocab[idx].isalnum()] \n",
    "        for comp in model.components_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-clinton",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "instructional-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stopped-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=10, n_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "comparable-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_matrix = lsa.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "prerequisite-astronomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 25132)\n",
      "(2008, 10)\n",
      "(10, 25132)\n"
     ]
    }
   ],
   "source": [
    "print(bow_matrix.shape) # hidden\n",
    "print(lsa_matrix.shape) # weight / code\n",
    "print(lsa.components_.shape) # fitur / topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "traditional-perth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['presiden', 'indonesia', 'pemerintah', 'dpr'],\n",
       " ['presiden', 'dpr', 'ketua', 'partai', 'mpr', 'tandjung'],\n",
       " ['pemerintah', 'rp', 'indonesia', 'bank', 'persen', 'utang'],\n",
       " ['rp', 'tandjung', 'dana', 'bulog', 'hukum', 'harga'],\n",
       " ['presiden', 'air', 'banjir', 'harga', 'rp', 'dpr'],\n",
       " ['harga', 'beras', 'rp', 'bbm'],\n",
       " ['mpr', 'konstitusi', 'bppn', 'uud'],\n",
       " ['indonesia', 'mpr', 'konstitusi', 'uud', 'perubahan', '1945'],\n",
       " ['pemerintah', 'dpr', 'israel', 'bppn', 'kota', 'aceh'],\n",
       " ['massa', 'rupiah', 'bunga', 'mpr', 'bank', 'suku']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-proposal",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "vocal-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hungarian-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "located-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_matrix = lda.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "filled-emergency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hukum', 'tandjung', 'agung', 'tim'],\n",
       " ['rumah', 'polisi', 'orang', 'jakarta'],\n",
       " ['pemerintah', 'rp', 'bppn', 'utang'],\n",
       " ['presiden', 'dpr', 'ketua', 'politik'],\n",
       " ['israel', 'aceh', 'keamanan', 'pemerintah'],\n",
       " ['indonesia', 'rp', 'dollar', 'as'],\n",
       " ['kota', 'warga', 'orang', 'korban'],\n",
       " ['indonesia', 'beras', 'harga', 'petani'],\n",
       " ['banjir', 'jakarta', 'air', 'jalan'],\n",
       " ['pesawat', 'pt', 'bca', 'ka']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-relaxation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-headset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
